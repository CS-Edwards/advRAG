{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -q python-dotenv\n",
    "! pip install -q neo4j\n",
    "! pip install -q langchain\n",
    "! pip install -q langchain-openai\n",
    "! pip install -q tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = os.getenv(\"URL\")\n",
    "os.environ[\"NEO4J_USERNAME\"]= os.getenv(\"USERNAME\")\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"PASSWORD2\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAIKEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "import sys\n",
    "sys.path.append('../utils')  \n",
    "from helper import write_chunks_to_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphDB = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphDB.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Initialize Semantic Vector Index\n",
    "#\n",
    "# DOCS: https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/\n",
    "#\n",
    "\n",
    "vector_index_query=\"\"\" \n",
    "CALL db.index.vector.createNodeIndex(\n",
    "  'accreditation_index',\n",
    "  'Chunk',\n",
    "  'embedding',\n",
    "   1536,\n",
    "  'cosine'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "graphDB.query(vector_index_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5,\n",
       "  'name': 'accreditation_index',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Chunk'],\n",
       "  'properties': ['embedding'],\n",
       "  'indexProvider': 'vector-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': None,\n",
       "  'readCount': 0},\n",
       " {'id': 1,\n",
       "  'name': 'index_343aff4e',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'LOOKUP',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': None,\n",
       "  'properties': None,\n",
       "  'indexProvider': 'token-lookup-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2024, 4, 17, 5, 29, 23, 62000000, tzinfo=<UTC>),\n",
       "  'readCount': 802},\n",
       " {'id': 2,\n",
       "  'name': 'index_f7700477',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'LOOKUP',\n",
       "  'entityType': 'RELATIONSHIP',\n",
       "  'labelsOrTypes': None,\n",
       "  'properties': None,\n",
       "  'indexProvider': 'token-lookup-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': None,\n",
       "  'readCount': 0},\n",
       " {'id': 3,\n",
       "  'name': 'unique_node',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'RANGE',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Session'],\n",
       "  'properties': ['sectionNum'],\n",
       "  'indexProvider': 'range-1.0',\n",
       "  'owningConstraint': 'unique_node',\n",
       "  'lastRead': None,\n",
       "  'readCount': 0}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphDB.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Query All Chunks without embedding\n",
    "#\n",
    "\n",
    "all_chunks_query = \"\"\" \n",
    "MATCH (c:Chunk) \n",
    "WHERE c.embedding IS null OR c.embedding = 0\n",
    "RETURN c\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# attach embedding to chunk.embedding\n",
    "vector_to_chunk_query = \"\"\" \n",
    "MATCH (c:Chunk {UUID: $UUID})\n",
    "SET c.embedding = $vector\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graphDB.query(all_chunks_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Vectors for Chunk.text and update Chunk.embedding\n",
    "#\n",
    "\n",
    "chunk_dataframe = write_chunks_to_df(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      208 non-null    object\n",
      " 1   nodeType  208 non-null    object\n",
      " 2   UUID      208 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#chunk_dataframe.head()\n",
    "chunk_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Chunk embedding function\n",
    "# \n",
    "# DOCS: https://platform.openai.com/docs/guides/embeddings/use-cases\n",
    "#\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client =OpenAI()\n",
    "\n",
    "#MODEL =  \"text-embedding-3-small\"\n",
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "def get_embedding(text, model = MODEL):\n",
    "\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_dataframe['vector'] = chunk_dataframe['text'].apply(lambda x:get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>UUID</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standard 1 strategic planning1.1 school mainta...</td>\n",
       "      <td>DATACHUNK</td>\n",
       "      <td>fb8549d4-efa5-4c55-a7d3-87522a416b98</td>\n",
       "      <td>[0.002811488462612033, 0.0041966927237808704, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>progress planned strategies expected outcomes ...</td>\n",
       "      <td>DATACHUNK</td>\n",
       "      <td>d6e18b0a-2aca-4de8-a294-e6160f186a0d</td>\n",
       "      <td>[-0.01016693189740181, 0.0034439638257026672, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1 maintenance strategic plan school mission ...</td>\n",
       "      <td>DATACHUNK</td>\n",
       "      <td>a67bc7ec-d5f2-44c4-a6e0-6d1e94af611b</td>\n",
       "      <td>[-0.008482272736728191, -0.010247484780848026,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plan . strategic plan developed refined engage...</td>\n",
       "      <td>DATACHUNK</td>\n",
       "      <td>e143576e-9893-4999-a5f7-a898d3388193</td>\n",
       "      <td>[0.0022559347562491894, 0.0026812339201569557,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>serve including level degree programs school o...</td>\n",
       "      <td>DATACHUNK</td>\n",
       "      <td>eecdf569-2c10-4574-ab4a-a8f6117a0b6d</td>\n",
       "      <td>[0.007008944638073444, 0.008684996515512466, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   nodeType  \\\n",
       "0  standard 1 strategic planning1.1 school mainta...  DATACHUNK   \n",
       "1  progress planned strategies expected outcomes ...  DATACHUNK   \n",
       "2  1.1 maintenance strategic plan school mission ...  DATACHUNK   \n",
       "3  plan . strategic plan developed refined engage...  DATACHUNK   \n",
       "4  serve including level degree programs school o...  DATACHUNK   \n",
       "\n",
       "                                   UUID  \\\n",
       "0  fb8549d4-efa5-4c55-a7d3-87522a416b98   \n",
       "1  d6e18b0a-2aca-4de8-a294-e6160f186a0d   \n",
       "2  a67bc7ec-d5f2-44c4-a6e0-6d1e94af611b   \n",
       "3  e143576e-9893-4999-a5f7-a898d3388193   \n",
       "4  eecdf569-2c10-4574-ab4a-a8f6117a0b6d   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.002811488462612033, 0.0041966927237808704, ...  \n",
       "1  [-0.01016693189740181, 0.0034439638257026672, ...  \n",
       "2  [-0.008482272736728191, -0.010247484780848026,...  \n",
       "3  [0.0022559347562491894, 0.0026812339201569557,...  \n",
       "4  [0.007008944638073444, 0.008684996515512466, -...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in chunk_dataframe.iterrows():\n",
    "\n",
    "    graphDB.query(vector_to_chunk_query, \n",
    "                params ={\n",
    "                    'UUID':row['UUID'],\n",
    "                    'vector':row['vector']\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_index_query = \"\"\"\n",
    "\n",
    "CALL db.index.vector.queryNodes('accreditation_index', 2, $inputVector)\n",
    "YIELD node AS responseNode, score\n",
    "\n",
    "RETURN responseNode.text, score \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"what are aacsb standards\"\n",
    "query_vector = get_embedding(query_text)\n",
    "query_result = graphDB.query(semantic_index_query, \n",
    "                                params={\n",
    "                                    \"inputVector\":query_vector\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'responseNode.text': '3.1 faculty sufficiency school adopts applies criteria documenting faculty members participating supporting consistent mission . school adapt guidance particular situation mission developing implementing criteria indicate school meeting spirit intent standard . criteria address activities required attain participating supporting status depth breadth activities expected within typical aacsb accreditation review cycle maintain participating supporting status . criteria periodically reviewed',\n",
       "  'score': 0.9091740846633911},\n",
       " {'responseNode.text': 'attain participating supporting status depth breadth activities expected within typical aacsb accreditation review cycle maintain participating supporting status . criteria periodically reviewed reflect focus continuous improvement . normally participating faculty members deliver least 75 percent school teaching globally i.e . across entire accredited unit participating faculty members deliver least 60 percent teaching within discipline regardless whether school degree major concentration etc .',\n",
       "  'score': 0.9044413566589355}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Standard QA\n",
    "#\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "VECTOR_INDEX_NAME = 'accreditiation-index'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY='embedding'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the knowledge graph in a RAG application\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "graphDB.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graphDB,\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
    "    validate_cypher=True, # Validate relationship directions\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (s:Standard {source: 'AACSB'}) RETURN s\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Tell me about AACSB standards',\n",
       " 'result': \"I don't know the answer.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cypher_chain.invoke({\"query\": \"How many learning objectives are assessed\"})\n",
    "#cypher_chain.invoke({\"query\": \"Which student learning goals were identified\"}) # does not know\n",
    "#cypher_chain.invoke({\"query\": \"What are the descriptions of the Learning goal\"}) ## does not know , see still Learning goal example\n",
    "cypher_chain.invoke({\"query\": \"Tell me about AACSB standards\"}) ## does not know , see still Learning goal example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the box LLM genreate cypher queries are not producing any results, OR are producing errors. @TODO, provide some examples to the mode an oppopriate queries based on the schema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain  = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  LangChain Docs: https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever/\n",
    "#     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "\n",
    "\n",
    "def extract_list(llm_result):\n",
    "    content = llm_result.content\n",
    "    return content.split(\"\\\\n\")\n",
    "\n",
    "def generate_multi_question(question):\n",
    "\n",
    "    system_prompt = f\"\"\" \n",
    "\n",
    "    # Instruction\n",
    "    You are an AI language model assistant. Your task is to generate three \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by new line. \n",
    "    \n",
    "    # Format Rules\n",
    "    DO NOT NUMBER THE LIST\n",
    "    Original question: {question}\n",
    "    \"\"\" \n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "    result = llm.invoke(system_prompt)\n",
    "    query_list = extract_list(result)\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "    return {'original_query': question, 'generated_query_list': query_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_multi_question_aacsb(question: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    For queries relating to the AACSB standards, generates list three different versions\n",
    "    of the user's input query. Used downstream for multiquery retrieval.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, any]: A dictionary containing the original user question and the generated list of alternative \n",
    "        questions. Keys include 'original_query' for the original question and 'generated_query_list' for the list \n",
    "        of alternative questions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    system_prompt = f\"\"\" \n",
    "\n",
    "    # Instruction\n",
    "    You are an AI language model assistant. Your task is to generate three \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search, by providing precise questions.\n",
    "    Provide these alternative questions separated by new line. \n",
    "\n",
    "    # Important Context: AACSB\n",
    "    The questions you generate are directly related to extracting useful information on the \n",
    "    AACSB accrediation standards. The questions you generate will be used as vector database index\n",
    "    queries that contain information on:\n",
    "\n",
    "    - formal AACSB descriptions\n",
    "    - documentation that supports each standard \n",
    "    - basis for evaluation of the standards \n",
    "    - relevent definitions of terms used in the standard descriptions.\n",
    "\n",
    "    The AACSB Website provides the following summary of their work:\n",
    "    AACSB accreditation is known, worldwide, as the longest-standing, most recognized form of \n",
    "    specialized accreditation that an institution and its business programs can earn. \n",
    "    Accreditation is a voluntary, nongovernmental process that includes a rigorous external review \n",
    "    of a school's mission, faculty qualifications, curricula, and ability to provide the highest-quality programs.\n",
    "    \n",
    "    # Format Rules\n",
    "    DO NOT NUMBER THE LIST\n",
    "    DO NOT ANSWER THE QUESTION\n",
    "    Original question: {question}\n",
    "    \"\"\" \n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "    result = llm.invoke(system_prompt)\n",
    "    query_list = extract_list(result)  \n",
    "\n",
    "\n",
    "\n",
    "    return {'original_query': question, 'generated_query_list': query_list, 'cat':'AACSB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def generate_multi_question_institution(question: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    For school specific, or academic institution specific, queries. Generates list three different versions\n",
    "    of the user's input query. Used downstream for multiquery retrieval.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, any]: A dictionary containing the original user question and the generated list of alternative \n",
    "        questions. Keys include 'original_query' for the original question and 'generated_query_list' for the list \n",
    "        of alternative questions.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    system_prompt = f\"\"\" \n",
    "\n",
    "    # Instruction\n",
    "    You are an AI language model assistant. Your task is to generate three \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search, by providing precise questions.\n",
    "    Provide these alternative questions separated by new line. \n",
    "\n",
    "    # Important Context: Academic Institution\n",
    "    The questions you generate are directly related to extracting useful information about a School\n",
    "    of Business.  The questions you generate will be used as vector database index\n",
    "    queries that contain information on:\n",
    "\n",
    "    - Strategic Plan, Mission and Fiscal Resources\n",
    "    - Academic Departments in the School of Business inluding not limited to : Accounting, Marketing, Management, Finance, Entreprenuership\n",
    "    - Student Services and Student Organizations \n",
    "    - Program Goals, Learning Objectives and Curriculum Assessment\n",
    "    - Continuous Improvement\n",
    "\n",
    "\n",
    "    # Format Rules\n",
    "    DO NOT NUMBER THE LIST\n",
    "    DO NOT ANSWER THE QUESTION\n",
    "    Original question: {question}\n",
    "    \"\"\" \n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "    result = llm.invoke(system_prompt)\n",
    "    query_list = extract_list(result)  \n",
    "\n",
    "\n",
    "\n",
    "    return {'original_query': question, 'generated_query_list': query_list, 'cat':'INSTITUTION'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def generate_sub_questions_hybrid(question: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    For queries relating to both AACSB accreditation AND Academic Institution (School) information .\n",
    "    Generates two distinct sub questions based on the user's input query. Used downstream for multiquery retrieval.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, any]: A dictionary containing the original user question and the generated list of alternative \n",
    "        questions. Keys include 'original_query' for the original question and 'generated_query_list' for the list \n",
    "        of alternative questions.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    system_prompt = f\"\"\" \n",
    "\n",
    "    # Instruction\n",
    "    You are an AI language model assistant. Your task is to evalute the users input query and \n",
    "    divide the query into two and ONLY TWO sub questions. The first sub questions should address the portion\n",
    "    of the user query that relates to the AACSB Standards, the second subquestion should relate the institution\n",
    "    specific portion of the query. Your overall objective is to break down the complex user query into the \n",
    "    two distinct sub questions.  Provide these alternative questions separated by new line. \n",
    "\n",
    "    # Important Context: Sub \n",
    "    \n",
    "    ## 1. AACSB Standard sub question:\n",
    "    AACSB sub question may related to accreditation content such as:\n",
    "\n",
    "    - formal AACSB descriptions\n",
    "    - documentation that supports each standard \n",
    "    - basis for evaluation of the standards \n",
    "    - relevent definitions of terms used in the standard descriptions.\n",
    "\n",
    "    The AACSB Website provides the following summary of their work:\n",
    "    AACSB accreditation is known, worldwide, as the longest-standing, most recognized form of \n",
    "    specialized accreditation that an institution and its business programs can earn. \n",
    "    Accreditation is a voluntary, nongovernmental process that includes a rigorous external review \n",
    "    of a school's mission, faculty qualifications, curricula, and ability to provide the highest-quality programs.\n",
    "\n",
    "\n",
    "    ## 2. Academic Instiution sub question:\n",
    "    Academic Instiution sub question may relate to School of Business content such as:\n",
    "\n",
    "    - Strategic Plan, Mission and Fiscal Resources\n",
    "    - Academic Departments in the School of Business inluding not limited to : Accounting, Marketing, Management, Finance, Entreprenuership\n",
    "    - Student Services and Student Organizations \n",
    "    - Program Goals, Learning Objectives and Curriculum Assessment\n",
    "    - Continuous Improvement\n",
    "\n",
    "\n",
    "    # Format Rules\n",
    "    DO NOT NUMBER THE LIST\n",
    "    DO NOT ANSWER THE QUESTION\n",
    "    Original question: {question}\n",
    "    \"\"\" \n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "    result = llm.invoke(system_prompt)\n",
    "    query_list = extract_list(result)  \n",
    "\n",
    "\n",
    "\n",
    "    return {'original_query': question, 'generated_query_list': query_list, 'cat':'HYBRID'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"how should I prepare for extended travel\"\n",
    "\n",
    "result = generate_multi_question(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- What are some tips for preparing for an extended travel?\n",
      "- Can you provide advice on getting ready for extended travel?\n",
      "- What steps should I take to prepare for a long trip?\n",
      "- How can I best get myself ready for an extended travel?\n",
      "- Are there any recommendations for preparing for a lengthy journey?\n"
     ]
    }
   ],
   "source": [
    "for r in result['generated_query_list']:\n",
    "    print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_query = \"Our accountind department recently  updated the curriculum to include carbon footprint, does this reflect the sustainability standard \"\n",
    "test_hybrid_query = generate_sub_questions_hybrid(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_query': 'Our accountind department recently  updated the curriculum to include carbon footprint, does this reflect the sustainability standard ',\n",
       " 'generated_query_list': ['Alternative questions:\\n1. What are the formal AACSB descriptions and documentation that support the sustainability standard?\\n2. How does the updated curriculum in our accounting department align with the sustainability standard?'],\n",
       " 'cat': 'HYBRID'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hybrid_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "\n",
    "def run_conversation(user_query:str)->str:\n",
    "    \"\"\"\n",
    "    Run a conversation with OpenAI's language model, providing the user query and available functions to the model.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the language model.\n",
    "\n",
    "    Step 1: Send the conversation and available functions to the model.\n",
    "        - Each function is described with its name, description, and parameters.\n",
    "        - Three functions are available:\n",
    "            1. generate_multi_question_aacsb: Generates three different versions of the user's input query\n",
    "               related to AACSB standards.\n",
    "            2. generate_multi_question_institution: Generates three different versions of the user's input query\n",
    "               for school-specific or academic institution-specific queries.\n",
    "            3. generate_sub_questions_hybrid: Generates two distinct sub-questions based on the user's input query,\n",
    "               relating to both AACSB accreditation and academic institution (school) information.\n",
    "\n",
    "    Returns the response from the language model, specifically the first choice message from the available choices.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_multi_question_aacsb\",\n",
    "                \"description\": \"For queries relating to the AACSB standards, generates list three different versions of the user's input query. Used downstream for multiquery retrieval.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Input user query\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"question\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_multi_question_institution\",\n",
    "                \"description\": \"For school specific, or academic institution specific, queries. Generates list three different versions of the user's input query. Used downstream for multiquery retrieval.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Input user query\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"question\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_sub_questions_hybrid\",\n",
    "                \"description\": \"For queries relating to both AACSB accreditation AND Academic Institution (School) information. Generates two distinct sub questions based on the user's input query. Used downstream for multiquery retrieval.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Input user query\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"question\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"AACSB standards on sustainability\"\n",
    "result = run_conversation(input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_multi_question_aacsb , AACSB standards on sustainability, \n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# function_name =  result.tool_calls[0].function.name\n",
    "# function_args = json.loads(result.tool_calls[0].function.arguments)['question']\n",
    "# print(f\"{function_name} , {function_args}, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_query': 'AACSB standards on sustainability', 'generated_query_list': ['1. What are the AACSB accrediation standards on sustainability?\\n2. How does AACSB define sustainability in their accrediation standards?\\n3. Can you provide information on the AACSB standards related to sustainability?']}\n"
     ]
    }
   ],
   "source": [
    "# function = globals()[function_name]\n",
    "# print(function(function_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def execute_route_function(conv_result: any)->any:\n",
    "    \"\"\"\n",
    "    Execute a route function based on the provided conversation result.\n",
    "\n",
    "    Args:\n",
    "        conv_result (any): The conversation result containing information about the function to execute.\n",
    "\n",
    "    Returns:\n",
    "        any: The result of executing the route function.\n",
    "\n",
    "    Extracts the name and arguments of the route function from the conversation result and then\n",
    "    dynamically executes the function using the extracted information.\n",
    "\n",
    "    Note:\n",
    "        - The function_name and function_args are extracted from the tool_calls attribute of the conversation result.\n",
    "        - The function_name is used to retrieve the actual function from the global namespace.\n",
    "        - The function_args are passed as arguments to the retrieved function.\n",
    "    \"\"\"\n",
    "\n",
    "    function_name =  result.tool_calls[0].function.name\n",
    "    function_args = json.loads(result.tool_calls[0].function.arguments)['question']\n",
    "    function = globals()[function_name]\n",
    "    return function(function_args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_routing_pipeline(user_query):\n",
    "    \"\"\"\n",
    "    Run a conversation with OpenAI's language model using the provided user query and then execute the route function.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The result of executing the route function.\n",
    "\n",
    "    This function serves as a pipeline for querying and routing based on the user's input.\n",
    "    It first runs a conversation with OpenAI's language model using the provided user query.\n",
    "    The result of the conversation is then passed to the execute_route_function to determine and execute the appropriate route function.\n",
    "    The result of executing the route function is returned as a dictionary.\n",
    "    \"\"\"\n",
    "    result = run_conversation(user_query)\n",
    "    return execute_route_function(result) #dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_query_in = \"AACSB standards on sustainability\"\n",
    "pipeline_result = query_routing_pipeline(test_query_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_query': 'AACSB standards on sustainability',\n",
       " 'generated_query_list': ['1. What are the AACSB standards for sustainability?\\n2. Can you provide information on the AACSB accreditation standards related to sustainability?\\n3. How does the AACSB incorporate sustainability into its accreditation standards?'],\n",
       " 'cat': 'AACSB'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(query_dict, cypher_chain=cypher_chain):\n",
    "\n",
    "    context_data = []\n",
    "\n",
    "    if query_dict['cat'] != 'HYBRID':\n",
    "        # multiqueries -- case A\n",
    "        # single cypher query for original query\n",
    "        for q in query_dict['generated_query_list']:\n",
    "            query_vector = get_embedding(q)\n",
    "            query_result = graphDB.query(semantic_index_query, \n",
    "                                params={\n",
    "                                    \"inputVector\":query_vector\n",
    "                                })\n",
    "            query_text = [text['responseNode.text'] for text in query_result]\n",
    "            context_data.extend(query_text)\n",
    "        \n",
    "        cypher_result = cypher_chain.invoke({\"query\": query_dict['original_query']})\n",
    "\n",
    "        if \"I don't know the answer\" not in cypher_result['result']:\n",
    "            context_data.append(cypher_result['result'])\n",
    "            \n",
    "\n",
    "    \n",
    "    else:\n",
    "        # subqueries -- case B\n",
    "        # cypher query for each subquery\n",
    "        for q in query_dict[generated_query_list]:\n",
    "            query_vector = get_embedding(q)\n",
    "            query_result = graphDB.query(semantic_index_query, \n",
    "                                params={\n",
    "                                    \"inputVector\":query_vector\n",
    "                                })\n",
    "            query_text = [text['responseNode.text'] for text in query_result]\n",
    "            context_data.extend(query_text)\n",
    "\n",
    "            cypher_result = cypher_chain.invoke({\"query\": q})\n",
    "\n",
    "            if \"I don't know the answer\" not in cypher_result['result']:\n",
    "                context_data.append(cypher_result['result'])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #if not hybrid\n",
    "    ### loop through multiqueries\n",
    "    #### call embedding function on each and retrieve data from db\n",
    "    #### append to  context data\n",
    "    ### call cypher query, append results to cyher data\n",
    "\n",
    "    #else:\n",
    "    ## loop through sub queries\n",
    "    ### call embedding and retrieve append resutls to context data\n",
    "    ### call cypher, append results to context data\n",
    "\n",
    "    return ', '.join(context_data) #return context data as a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (s:Standard {title: \"AACSB standards on sustainability\"}) RETURN s\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ret_result = retriever(pipeline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1 faculty sufficiency school adopts applies criteria documenting faculty members participating supporting consistent mission . school adapt guidance particular situation mission developing implementing criteria indicate school meeting spirit intent standard . criteria address activities required attain participating supporting status depth breadth activities expected within typical aacsb accreditation review cycle maintain participating supporting status . criteria periodically reviewed, attain participating supporting status depth breadth activities expected within typical aacsb accreditation review cycle maintain participating supporting status . criteria periodically reviewed reflect focus continuous improvement . normally participating faculty members deliver least 75 percent school teaching globally i.e . across entire accredited unit participating faculty members deliver least 60 percent teaching within discipline regardless whether school degree major concentration etc .'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(original_query, context_string, model = \"gpt-3.5-turbo-16k\"):\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    # Instruction:\n",
    "    You are an AI assistant generating a thorough and thoughtful response to a user query.\n",
    "    You are to generate a response that answers their query solely based on the context provided below\n",
    "    do not use any other outside information. The grounding context information has been retrieved from\n",
    "    a database which is the absolute knowledge source. \n",
    "\n",
    "    # User Query:\n",
    "    {original_query}\n",
    "\n",
    "    # Grounding Context:\n",
    "    {context_string}\n",
    "\n",
    "    # Output Style\n",
    "    Your tone should be professional. And your response should be detailed, as this information\n",
    "    will be used to generate reports. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(model=model, temperature=0)\n",
    "    result = llm.invoke(system_prompt)\n",
    "    content = result.content\n",
    "     \n",
    "\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(test_query_in, ret_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the AACSB standards on sustainability, schools are required to adopt and apply criteria that document faculty members' participation and support of the consistent mission. These criteria should be adapted to the specific situation and mission of the school, and should indicate how the school is meeting the spirit and intent of the standard. The criteria should address the activities required to attain participating and supporting status, both in terms of depth and breadth of activities. These activities are expected to be within the typical AACSB accreditation review cycle, and should be maintained to maintain participating and supporting status.\\n\\nThe criteria should be periodically reviewed to reflect a focus on continuous improvement. In terms of faculty involvement, it is expected that participating faculty members deliver at least 75 percent of the school's teaching globally, across the entire accredited unit. Additionally, participating faculty members should deliver at least 60 percent of the teaching within their discipline, regardless of whether the school offers a degree, major, concentration, or other specialization in that discipline.\\n\\nThese standards ensure that schools are actively engaging faculty members in supporting the mission of sustainability and maintaining high-quality education. By meeting these criteria, schools demonstrate their commitment to sustainability and continuous improvement in their educational programs.\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
